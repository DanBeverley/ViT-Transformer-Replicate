{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9657a68-e979-4407-8d54-543913e40e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input for ConvNet is fixed of [224,224,3]\n",
    "#Conv layer has the kernel_size = (3,3) , (1,1) with the stride fixed to 1 pixel . Padding = 1 for (3 ,3) layer\n",
    "#Linear follow up by non-linearity\n",
    "#Consist of five max pooling layers , followed some of the conv layers with kernel_size = (2,2) and stride of 2\n",
    "#A stack of convolutional layers followed by three linear layers , first two have 4096 , third has 1000 classification\n",
    "#The final is softmax layer\n",
    "#The width of conv. layers (the number of channels) is rather small, starting from 64 in the first layer and then\n",
    "#First two fully connected layer has dropout(p = 0.5)\n",
    "#increasing by a factor of 2 after each max-pooling layer, until it reaches 512.\n",
    "#optimizer = torch.optim.SGD(momentum = 0.9 , weight_decay = 5*10**-4 , lr = 10**-2)\n",
    "#nn.MaxPool2d(kernel_size = 2 , stride = 1)\n",
    "#Lr is decrease to a factor of 10 if validation set accuracy stop improving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33184a6d-b193-4ee6-ac21-ceaa8d52e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from going_modular import data_setup , dataloader_setup , engine\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "VGG_types = {\n",
    "\"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "\"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "\"VGG16\": [64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\",],\n",
    "\"VGG19\": [64,64,\"M\",128,128,\"M\",256,256,256,256,\"M\",512,512,512,512,\n",
    "          \"M\",512,512,512,512,\"M\",],}\n",
    "VGGtype = \"VGG16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de911665-a951-4ce9-aaa6-019215bc940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self , in_channels = 3 , num_classes = 1000):\n",
    "        super(VGG , self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features = 512*7*7 , out_features = 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(in_features = 4096 , out_features = 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p = 0.5),\n",
    "            nn.Linear(in_features = 4096 , out_features = num_classes)\n",
    "        )\n",
    "    def forward(self , x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0],-1) #Flattening every dimension except batch_size\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "                layers += [\n",
    "                    nn.Conv2d(in_channels = in_channels , out_channels = out_channels, \n",
    "                              kernel_size = 3 , padding = 1 , stride = 1),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU()\n",
    "                ]\n",
    "                in_channels = x\n",
    "            elif x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size = 2 , stride = 2)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad9b014d-df67-4e9e-a767-ec13c3107cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.randn(1,3,224,224).to(device)\n",
    "model = VGG(in_channels = 3 , num_classes = 3).to(device)\n",
    "#print(model)\n",
    "print(model(random_tensor).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08a0caf-b506-44f0-a10a-c76484af6574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory exists, skipping download.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms , datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "image_path = data_setup.download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                           destination=\"pizza_steak_sushi\")\n",
    "train_dir = image_path/\"train\"\n",
    "test_dir = image_path/\"test\"\n",
    "\n",
    "def create_dataloaders(train_dir , test_dir , transform , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS):\n",
    "    train_data = datasets.ImageFolder(root = train_dir , transform = transform)\n",
    "    test_data = datasets.ImageFolder(root = test_dir , transform = transform)\n",
    "\n",
    "    num_classes = train_data.classes\n",
    "\n",
    "    train_dataloader = DataLoader(train_data , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS ,\n",
    "                                  pin_memory = True ,shuffle = True)\n",
    "    test_dataloader = DataLoader(test_data , batch_size = BATCH_SIZE , num_workers = NUM_WORKERS ,\n",
    "                                pin_memory = True , shuffle = False)\n",
    "    return train_dataloader , test_dataloader , num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8b335a4-f27d-427a-9ebe-96d1ead05039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model , train_dataloader, loss_fn , optimizer , device = device):\n",
    "    model.train()\n",
    "    train_loss , train_acc = 0,0\n",
    "    for batch , (x,y) in enumerate(train_dataloader):\n",
    "        x , y = x.to(device) , y.to(device)\n",
    "        y_preds = model(x)\n",
    "        loss = loss_fn(y_preds, y)\n",
    "        train_loss+= loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        y_preds_class = torch.argmax(torch.softmax(y_preds , dim = 1), dim = 1)\n",
    "        train_acc += (y_preds_class == y).sum().item()/len(y_preds)\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    return train_loss, train_acc\n",
    "def test_step(model , test_dataloader , loss_fn , device = device):\n",
    "    model.eval()\n",
    "    test_loss , test_acc = 0,0\n",
    "    with torch.inference_mode():\n",
    "        for batch , (x,y) in enumerate(test_dataloader):\n",
    "            x , y = x.to(device) , y.to(device)\n",
    "            y_preds = model(x)\n",
    "            loss = loss_fn(y_preds , y)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            y_preds_class = torch.argmax(y_preds , dim = 1)\n",
    "            test_acc += (y_preds_class == y).sum().item()/len(y_preds_class)\n",
    "    test_loss/=len(test_dataloader)\n",
    "    test_acc/=len(test_dataloader)\n",
    "    return test_loss , test_acc\n",
    "def train(model , train_dataloader, test_dataloader , loss_fn , optimizer , epochs , device = device):\n",
    "    results = {\"train_loss\":[],\n",
    "              \"train_acc\":[],\n",
    "              \"test_loss\":[],\n",
    "              \"test_acc\":[]}\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss , train_acc = train_step(model = model , train_dataloader = train_dataloader , \n",
    "                                      loss_fn = loss_fn ,\n",
    "                                      optimizer = optimizer , \n",
    "                                      device = device)\n",
    "        test_loss , test_acc = test_step(model = model , test_dataloader = test_dataloader,\n",
    "                                        loss_fn = loss_fn,\n",
    "                                        device = device)\n",
    "        print(\n",
    "          f\"Epoch: {epochs+1} | \"\n",
    "          f\"train_loss: {train_loss:.4f} | \"\n",
    "          f\"train_acc: {train_acc:.4f} | \"\n",
    "          f\"test_loss: {test_loss:.4f} | \"\n",
    "          f\"test_acc: {test_acc:.4f}\"\n",
    "         )\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cccc37d7-d989-4abd-a60a-b16d40d13b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "606d42a52eb9435db6eeb653db84d622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | train_loss: 1.3738 | train_acc: 0.3984 | test_loss: 1.0067 | test_acc: 0.5417\n",
      "Epoch: 11 | train_loss: 1.9225 | train_acc: 0.3125 | test_loss: 29.2798 | test_acc: 0.3920\n",
      "Epoch: 11 | train_loss: 2.0587 | train_acc: 0.4492 | test_loss: 248.3902 | test_acc: 0.5417\n",
      "Epoch: 11 | train_loss: 3.4229 | train_acc: 0.3906 | test_loss: 6914.2114 | test_acc: 0.5417\n",
      "Epoch: 11 | train_loss: 8.6835 | train_acc: 0.3281 | test_loss: 137.3648 | test_acc: 0.2604\n",
      "Epoch: 11 | train_loss: 10.1790 | train_acc: 0.3945 | test_loss: 404.4097 | test_acc: 0.1979\n",
      "Epoch: 11 | train_loss: 1.7417 | train_acc: 0.4258 | test_loss: 40.6589 | test_acc: 0.1979\n",
      "Epoch: 11 | train_loss: 2.8186 | train_acc: 0.3438 | test_loss: 30.9871 | test_acc: 0.4517\n",
      "Epoch: 11 | train_loss: 4.2234 | train_acc: 0.2930 | test_loss: 34.5978 | test_acc: 0.5417\n",
      "Epoch: 11 | train_loss: 6.7339 | train_acc: 0.4258 | test_loss: 132.1926 | test_acc: 0.3305\n"
     ]
    }
   ],
   "source": [
    "weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "auto_transform = weights.transforms()\n",
    "\n",
    "train_dataloader , test_dataloader , num_classes = create_dataloaders(train_dir = train_dir \n",
    "                                                                    , test_dir = test_dir , \n",
    "                                                                     transform = auto_transform,\n",
    "                                                                     batch_size = BATCH_SIZE,\n",
    "                                                                     num_workers = NUM_WORKERS)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params = model.parameters() , momentum = 0.9 , lr = 0.01)\n",
    "\n",
    "model_results = train(model = model,\n",
    "                     train_dataloader = train_dataloader,\n",
    "                     test_dataloader = test_dataloader,\n",
    "                     loss_fn = loss_fn,\n",
    "                     optimizer = optimizer,\n",
    "                     epochs = 10,\n",
    "                     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e721cf-52c4-40f7-a8d9-4b3f7f58bd46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
